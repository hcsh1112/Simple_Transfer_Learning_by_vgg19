{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 256, 256\n",
    "train_data_dir = \"training_set\"\n",
    "validation_data_dir = \"validation_set\"\n",
    "nb_train_samples = 1000\n",
    "nb_validation_samples = 200 \n",
    "batch_size = 50\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using VGG19 to do transfer learning\n",
    "#### Creat a fully connected layer to classfy the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include top = the final level( fully connected )\n",
    "model = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "\n",
    "# Lock every layer in the VGG19( because the layers are already trained by imagenet ) \n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# creat a fully connected layer\n",
    "x = model.output\n",
    "x = Flatten()(x) # fully connected\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x) # avoid over fitting\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "# to classfy two labels\n",
    "predictions = Dense( 2, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model_final = Model(input = model.input, output = predictions)\n",
    "\n",
    "# compile the model \n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = 'adam', metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data Setting ( training/testing data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the train and test generators with data Augumentation \n",
    "train_datagen = ImageDataGenerator(\n",
    "rescale = 1./255,\n",
    "horizontal_flip = True,\n",
    "fill_mode = \"nearest\",\n",
    "zoom_range = 0.3,\n",
    "width_shift_range = 0.3,\n",
    "height_shift_range=0.3,\n",
    "rotation_range=30 )\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    "rescale = 1./255,\n",
    "horizontal_flip = True,\n",
    "fill_mode = \"nearest\",\n",
    "zoom_range = 0.3,\n",
    "width_shift_range = 0.3,\n",
    "height_shift_range=0.3,\n",
    "rotation_range=30)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "train_data_dir,\n",
    "target_size = (img_height, img_width),\n",
    "batch_size = batch_size, \n",
    "class_mode = \"categorical\")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "validation_data_dir,\n",
    "target_size = (img_height, img_width),\n",
    "class_mode = \"categorical\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set ealy stop to avoid the overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model according to the conditions  \n",
    "checkpoint = ModelCheckpoint(\"my_model.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=10)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=100, verbose=1, mode='auto')\n",
    "tb = keras.callbacks.TensorBoard( log_dir = './log' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "#### Using tensorboard to check the loss and acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model \n",
    "model_final.fit_generator(\n",
    "train_generator,\n",
    "samples_per_epoch = nb_train_samples,\n",
    "epochs = 5000,\n",
    "validation_data = validation_generator,\n",
    "nb_val_samples = nb_validation_samples,\n",
    "callbacks = [checkpoint, early, tb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
